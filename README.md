# Memory-based generation: Enabling LMs to handle long input texts by extracting useful information

As part of the course Computational Semantics for NLP at ETH Zurich, we are exploring different methods of enabling transformer-based LMs to handle 
long text sequences. 